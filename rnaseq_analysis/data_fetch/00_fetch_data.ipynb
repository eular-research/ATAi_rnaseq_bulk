{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching rnaseq raw data from ENA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(httr)\n",
    "library(jsonlite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data by project id: \n",
    " - Visit https://www.ebi.ac.uk/ena/browser/search \n",
    " - Search for the project you want to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with the study accession you are interested in \n",
    "accession <- \"PRJNA352076\"  \n",
    "\n",
    "fetch_ena_data <- function(accession) {\n",
    "  base_url <- \"https://www.ebi.ac.uk/ena/portal/api/search\"\n",
    "  query <- list(\n",
    "    result = \"read_run\",\n",
    "    query = paste(\"study_accession=\\\"\", accession, \"\\\"\", sep = \"\"),\n",
    "    fields = paste(\n",
    "      \"experiment_title,experiment_accession,experiment_alias,bam_bytes,bam_ftp,bam_md5,base_count,broker_name,center_name,\",\n",
    "      \"fastq_aspera,fastq_bytes,fastq_ftp,fastq_galaxy,fastq_md5,first_created,first_public,instrument_model,instrument_platform,\",\n",
    "      \"last_updated,library_layout,library_name,library_selection,library_source,library_strategy,nominal_length,nominal_sdev,\",\n",
    "      \"read_count,run_accession,run_alias,sample_accession,sample_alias,sample_title,scientific_name,secondary_sample_accession,\",\n",
    "      \"secondary_study_accession,sra_aspera,sra_bytes,sra_ftp,sra_galaxy,sra_md5,study_accession,study_alias,study_title,\",\n",
    "      \"submission_accession,submitted_aspera,submitted_bytes,submitted_format,submitted_ftp,submitted_galaxy,submitted_md5,tax_id\",\n",
    "      sep = \"\"\n",
    "    ),\n",
    "    format = \"json\"\n",
    "  )\n",
    "  \n",
    "  response <- GET(base_url, query = query)\n",
    "  \n",
    "  if (status_code(response) == 200) {\n",
    "    content <- content(response, as = \"text\", encoding = \"UTF-8\")\n",
    "    data <- fromJSON(content)\n",
    "    return(data)\n",
    "  } else {\n",
    "    stop(\"Failed to fetch data from ENA. Status code: \", status_code(response))\n",
    "  }\n",
    "}\n",
    "\n",
    "# the format of the file is: \n",
    "# center_name, experiment_title, instrument_model,instrument_platform, library_layout,library_name,sample_title,scientific_name, study_title, sra_ftp\n",
    "ena_data <- fetch_ena_data(accession)\n",
    "\n",
    "# Print the data\n",
    "write.csv(ena_data, \"./accession_data_to_file.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files and prepare csv for nf-rnaseq\n",
    "\n",
    "* You can download files or part of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m1\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m51\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (30): run_accession, experiment_accession, experiment_alias, fastq_aspe...\n",
      "\u001b[32mdbl\u001b[39m   (4): base_count, read_count, sra_bytes, tax_id\n",
      "\u001b[33mlgl\u001b[39m  (14): bam_bytes, bam_ftp, bam_md5, broker_name, center_name, library_na...\n",
      "\u001b[34mdate\u001b[39m  (3): first_created, first_public, last_updated\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "\n",
    "# Define the input CSV file (replace with your actual file path)\n",
    "input_file <- \"accession_data_to_file.csv\" # Change to your input file if different\n",
    "output_csv <- \"nextflow_samples.csv\"  # Output file for Nextflow\n",
    "\n",
    "# Set the option to download part of the file (TRUE for partial download, FALSE for full download)\n",
    "download_part_of_file <- TRUE  # Set to TRUE for partial download, FALSE for full file download\n",
    "\n",
    "# Function to download FASTQ files, either fully or a subset (100 reads)\n",
    "download_fastq <- function(fastq_ftp, sample_name, download_dir = \"fastq_files\", num_reads = NULL) {\n",
    "  # Ensure the download directory exists\n",
    "  if (!dir.exists(download_dir)) {\n",
    "    dir.create(download_dir)\n",
    "  }\n",
    "  \n",
    "  # Split the FTP links (since they are separated by ';')\n",
    "  fastq_links <- strsplit(fastq_ftp, \";\")[[1]]\n",
    "  \n",
    "  # Define output file paths based on sample name\n",
    "  fastq_1_file <- file.path(download_dir, paste0(sample_name, \"_1.fastq.gz\"))\n",
    "  fastq_2_file <- file.path(download_dir, paste0(sample_name, \"_2.fastq.gz\"))\n",
    "  \n",
    "  # If num_reads is specified, download only a subset (100 reads), otherwise download the entire file\n",
    "  if (!is.null(num_reads)) {\n",
    "    # Define how many lines to fetch (4 lines per read in FASTQ format)\n",
    "    num_lines <- num_reads * 4\n",
    "    \n",
    "    # Download the first portion of the FASTQ files\n",
    "    system(paste0(\"curl -s --range 0-\", num_lines, \"k ftp://\", fastq_links[1], \" | gzip > \", fastq_1_file))\n",
    "    system(paste0(\"curl -s --range 0-\", num_lines, \"k ftp://\", fastq_links[2], \" | gzip > \", fastq_2_file))\n",
    "    \n",
    "  } else {\n",
    "    # Download the entire FASTQ files\n",
    "    system(paste0(\"curl -o \", fastq_1_file, \" ftp://\", fastq_links[1]))\n",
    "    system(paste0(\"curl -o \", fastq_2_file, \" ftp://\", fastq_links[2]))\n",
    "  }\n",
    "  \n",
    "  return(list(fastq_1_file, fastq_2_file))\n",
    "}\n",
    "\n",
    "# Function to prepare Nextflow-compatible CSV\n",
    "prepare_nextflow_csv <- function(data, download_part = TRUE, num_reads = 100) {\n",
    "  # Initialize an empty list to store rows\n",
    "  nextflow_list <- list()\n",
    "  \n",
    "  # Loop through the data\n",
    "  for (i in 1:nrow(data)) {\n",
    "    # Convert the 'sample_title' to a valid sample name by replacing spaces with underscores\n",
    "    sample_name <- gsub(\" \", \"_\", data$sample_title[i])\n",
    "    \n",
    "    # Get the FASTQ FTP links\n",
    "    fastq_ftp <- data$fastq_ftp[i]\n",
    "    \n",
    "    # Download either a subset or the full FASTQ files\n",
    "    if (download_part) {\n",
    "      fastq_files <- download_fastq(fastq_ftp, sample_name, num_reads = num_reads)\n",
    "    } else {\n",
    "      fastq_files <- download_fastq(fastq_ftp, sample_name)\n",
    "    }\n",
    "    \n",
    "    # Append the row to the list (adding 'auto' strandedness)\n",
    "    nextflow_list[[i]] <- c(sample_name, fastq_files[[1]], fastq_files[[2]], \"auto\")\n",
    "  }\n",
    "  \n",
    "  # Convert the list to a data frame\n",
    "  nextflow_df <- as.data.frame(do.call(rbind, nextflow_list), stringsAsFactors = FALSE)\n",
    "  colnames(nextflow_df) <- c(\"sample\", \"fastq_1\", \"fastq_2\", \"strandedness\")\n",
    "  \n",
    "  # Write the data frame to a CSV file\n",
    "  write_csv(nextflow_df, output_csv)\n",
    "  message(\"Nextflow CSV has been saved to: \", output_csv)\n",
    "}\n",
    "\n",
    "# Read the input CSV file\n",
    "data <- read_csv(input_file)\n",
    "\n",
    "# Run the preparation function\n",
    "prepare_nextflow_csv(data, download_part = download_part_of_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
